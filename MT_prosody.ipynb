{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwf281iwmf4T",
        "outputId": "f987d64d-8f1b-45c2-d6ef-b290dee64eea"
      },
      "id": "Bwf281iwmf4T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "715b8157",
      "metadata": {
        "id": "715b8157"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import sentencepiece as spm\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b8ffd1e9",
      "metadata": {
        "id": "b8ffd1e9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Parameters\n",
        "BATCH_SIZE = 64\n",
        "EMBED_SIZE = 256\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 1\n",
        "LR = 0.001\n",
        "VOCAB_SIZE = 8000       # subword vocab size for each language\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a64be7d",
      "metadata": {
        "id": "3a64be7d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Load corpus\n",
        "data = pd.read_csv('sentences_with_audio_names.csv')  # columns: 'src','tgt', optional prosody cols\n",
        "\n",
        "# 2. Prepare and train SentencePiece models (once)\n",
        "#    Extract columns to plain text files for reliability, then train.\n",
        "with open('src.txt', 'w', encoding='utf-8') as f_src, open('tgt.txt', 'w', encoding='utf-8') as f_tgt:\n",
        "    for s, t in zip(data['src'], data['tgt']):\n",
        "        f_src.write(s.replace('\\n',' ').strip() + '\\n')\n",
        "        f_tgt.write(t.replace('\\n',' ').strip() + '\\n')\n",
        "\n",
        "\n",
        "#    Train SentencePiece on the extracted files\n",
        "#    This generates src_spm.model / src_spm.vocab and tgt_spm.model / tgt_spm.vocab\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    f\"--input=src.txt --model_prefix=src_spm --vocab_size={VOCAB_SIZE} \"\n",
        "    \"--model_type=bpe --unk_id=0 --pad_id=1 --bos_id=2 --eos_id=3\"\n",
        ")\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    f\"--input=tgt.txt --model_prefix=tgt_spm --vocab_size={VOCAB_SIZE} \"\n",
        "    \"--model_type=bpe --unk_id=0 --pad_id=1 --bos_id=2 --eos_id=3\"\n",
        ")\n",
        "\n",
        "# 3. Load SP models\n",
        "src_sp = spm.SentencePieceProcessor(model_file='src_spm.model')\n",
        "tgt_sp = spm.SentencePieceProcessor(model_file='tgt_spm.model')\n",
        "SRC_VOCAB = src_sp.get_piece_size()\n",
        "TGT_VOCAB = tgt_sp.get_piece_size()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RB2RQ1XEd0FL",
        "outputId": "223c0ea8-2579-4e2b-e74a-175e9127eef9"
      },
      "id": "RB2RQ1XEd0FL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     filename                                                src  \\\n",
              "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
              "1  LJ001-0002                     in being comparatively modern.   \n",
              "2  LJ001-0003  For although the Chinese took impressions from...   \n",
              "3  LJ001-0004  produced the block books, which were the immed...   \n",
              "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
              "\n",
              "                                                 tgt  \n",
              "0  ఎగ్జిబిషన్‌లో ప్రాతినిధ్యం వహించే అన్ని కళలు మ...  \n",
              "1                    తులనాత్మకంగా ఆధునికంగా ఉండటంలో.  \n",
              "2  ఎందుకంటే, నెదర్లాండ్స్‌లోని చెక్కలను కొట్టేవార...  \n",
              "3  నిజమైన ముద్రిత పుస్తకానికి తక్షణ పూర్వీకులు అయ...  \n",
              "4  పదిహేనవ శతాబ్దం మధ్యలో కదిలే లోహ అక్షరాల ఆవిష్...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-958b64c8-538b-44af-b651-c7fe0b85877a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LJ001-0001</td>\n",
              "      <td>Printing, in the only sense with which we are ...</td>\n",
              "      <td>ఎగ్జిబిషన్‌లో ప్రాతినిధ్యం వహించే అన్ని కళలు మ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LJ001-0002</td>\n",
              "      <td>in being comparatively modern.</td>\n",
              "      <td>తులనాత్మకంగా ఆధునికంగా ఉండటంలో.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LJ001-0003</td>\n",
              "      <td>For although the Chinese took impressions from...</td>\n",
              "      <td>ఎందుకంటే, నెదర్లాండ్స్‌లోని చెక్కలను కొట్టేవార...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LJ001-0004</td>\n",
              "      <td>produced the block books, which were the immed...</td>\n",
              "      <td>నిజమైన ముద్రిత పుస్తకానికి తక్షణ పూర్వీకులు అయ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LJ001-0005</td>\n",
              "      <td>the invention of movable metal letters in the ...</td>\n",
              "      <td>పదిహేనవ శతాబ్దం మధ్యలో కదిలే లోహ అక్షరాల ఆవిష్...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-958b64c8-538b-44af-b651-c7fe0b85877a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-958b64c8-538b-44af-b651-c7fe0b85877a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-958b64c8-538b-44af-b651-c7fe0b85877a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "616d68e4",
      "metadata": {
        "id": "616d68e4"
      },
      "outputs": [],
      "source": [
        "def add_special(ids, sos_id, eos_id):\n",
        "    return [sos_id] + ids + [eos_id]\n",
        "\n",
        "# Dataset class\n",
        "class MTDataset(Dataset):\n",
        "    def __init__(self, df, src_sp, tgt_sp, prosody_npz_path, prosody_dim=19):\n",
        "        self.src = df['src'].tolist()\n",
        "        self.tgt = df['tgt'].tolist()\n",
        "        self.filenames = df['filename'].tolist()\n",
        "        self.src_sp = src_sp\n",
        "        self.tgt_sp = tgt_sp\n",
        "        self.src_sos, self.src_eos = src_sp.bos_id(), src_sp.eos_id()\n",
        "        self.tgt_sos, self.tgt_eos = tgt_sp.bos_id(), tgt_sp.eos_id()\n",
        "\n",
        "        # Load prosody data from .npz file\n",
        "        self.prosody_data = dict(np.load(prosody_npz_path))  # Assuming prosody features are in a .npz file\n",
        "        self.prosody_dim = prosody_dim\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def encode(self, text, sp):\n",
        "        return sp.encode(text, out_type=int)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_ids = add_special(self.encode(self.src[idx], self.src_sp), self.src_sos, self.src_eos)\n",
        "        tgt_ids = add_special(self.encode(self.tgt[idx], self.tgt_sp), self.tgt_sos, self.tgt_eos)\n",
        "        filename = self.filenames[idx]\n",
        "\n",
        "        # Check if the filename exists in the prosody data\n",
        "        # print(self.prosody_data)\n",
        "        if filename in self.prosody_data.keys():\n",
        "            # print(filename)\n",
        "            pros = self.prosody_data[filename].astype(np.float32)\n",
        "            pros = pros.mean(axis=1)  # Take the mean over dim=1 to make it a fixed-size vector\n",
        "        else:\n",
        "            # If filename not found, generate a random prosody vector of size 19\n",
        "            # print(\"Generating random prosody vector\")\n",
        "            pros = np.random.rand(self.prosody_dim).astype(np.float32)\n",
        "\n",
        "        return torch.tensor(src_ids), torch.tensor(tgt_ids), torch.tensor(pros)\n",
        "\n",
        "\n",
        "# Collate function\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch, pros_batch = zip(*batch)\n",
        "    src_pad = pad_sequence(src_batch, padding_value=src_sp.pad_id(), batch_first=True)\n",
        "    tgt_pad = pad_sequence(tgt_batch, padding_value=tgt_sp.pad_id(), batch_first=True)\n",
        "    pros = torch.stack(pros_batch)\n",
        "    pros = pros.unsqueeze(1).expand(-1, src_pad.size(1), -1)\n",
        "    return src_pad.to(DEVICE), tgt_pad.to(DEVICE), pros.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset and dataloaders\n",
        "dataset = MTDataset(data, src_sp, tgt_sp, prosody_npz_path='prosody_features.npz')\n",
        "train_size = int(0.98 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "uveVbzYEY-L1"
      },
      "id": "uveVbzYEY-L1",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5268e47d",
      "metadata": {
        "id": "5268e47d"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, prosody_dim=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.input_dim = embed_size + prosody_dim  # Concatenating prosody features with embeddings\n",
        "        self.gru = nn.GRU(self.input_dim, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x, prosody):\n",
        "        if prosody is None:\n",
        "            raise ValueError(\"Prosody tensor should never be None\")\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Ensure prosody tensor matches sequence length and concatenate\n",
        "        prosody = prosody[:, :embedded.size(1), :]  # Ensure prosody has the same length as the sequence\n",
        "\n",
        "        # Concatenate prosody features with embeddings\n",
        "        embedded = torch.cat((embedded, prosody), dim=2)\n",
        "\n",
        "        # Pass through GRU\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
        "        self.gru = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.unsqueeze(1)\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        pred = self.fc_out(output.squeeze(1))\n",
        "        return pred, hidden\n",
        "\n",
        "# Seq2Seq model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt, prosody=None, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tgt.size()\n",
        "        outputs = torch.zeros(batch_size, tgt_len, TGT_VOCAB).to(DEVICE)\n",
        "        _, hidden = self.encoder(src, prosody)\n",
        "        input = tgt[:, 0]\n",
        "        for t in range(1, tgt_len):\n",
        "            out, hidden = self.decoder(input, hidden)\n",
        "            outputs[:, t, :] = out\n",
        "            input = tgt[:, t] if torch.rand(1).item() < teacher_forcing_ratio else out.argmax(1)\n",
        "        return outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bleu(model, dataloader):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "\n",
        "    # print(\"Sample translations:\\n\")\n",
        "    with torch.no_grad():\n",
        "        for i, (src, tgt, pros) in enumerate(dataloader):\n",
        "            _, hidden = model.encoder(src, pros)\n",
        "            input = torch.tensor([tgt_sp.bos_id()] * src.size(0)).to(DEVICE)\n",
        "            outputs = []\n",
        "            for _ in range(50):\n",
        "                out, hidden = model.decoder(input, hidden)\n",
        "                input = out.argmax(1)\n",
        "                outputs.append(input)\n",
        "            outputs = torch.stack(outputs, dim=1).cpu().tolist()\n",
        "            tgt = tgt.cpu().tolist()\n",
        "            for ref, hyp in zip(tgt, outputs):\n",
        "                ref_tokens = [t for t in ref[1:] if t not in [tgt_sp.pad_id(), tgt_sp.eos_id()]]\n",
        "                hyp_tokens = [t for t in hyp if t not in [tgt_sp.pad_id(), tgt_sp.eos_id()]]\n",
        "                refs.append([ref_tokens])\n",
        "                hyps.append(hyp_tokens)\n",
        "                if i < 5:\n",
        "                    ref_text = tgt_sp.decode(ref_tokens)\n",
        "                    hyp_text = tgt_sp.decode(hyp_tokens)\n",
        "    bleu = corpus_bleu(refs, hyps, smoothing_function=SmoothingFunction().method4)\n",
        "    print(f\"BLEU Score: {bleu:.4f}\")"
      ],
      "metadata": {
        "id": "fPFUILT4op3v"
      },
      "id": "fPFUILT4op3v",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a9bdd40f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9bdd40f",
        "outputId": "32968837-ea7d-431a-c41c-8ac124ce36e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.3427\n",
            "Epoch 2, Loss: 6.7586\n",
            "Epoch 3, Loss: 6.3134\n",
            "Epoch 4, Loss: 5.9158\n",
            "Epoch 5, Loss: 5.6191\n",
            "Epoch 6, Loss: 5.3255\n",
            "Epoch 7, Loss: 5.0978\n",
            "Epoch 8, Loss: 4.8639\n",
            "Epoch 9, Loss: 4.6325\n",
            "Epoch 10, Loss: 4.4278\n"
          ]
        }
      ],
      "source": [
        "def train(model, dataloader, optimizer, criterion, epochs=10):\n",
        "    model.to(DEVICE)\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        total = 0\n",
        "        for src_batch, tgt_batch, pros in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(src_batch, tgt_batch, pros)\n",
        "            out = preds[:, 1:].reshape(-1, preds.size(-1))\n",
        "            tgt = tgt_batch[:, 1:].reshape(-1)\n",
        "            loss = criterion(out, tgt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += loss.item()\n",
        "        print(f\"Epoch {ep+1}, Loss: {total/len(dataloader):.4f}\")\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS, prosody_dim=19)\n",
        "decoder = Decoder(TGT_VOCAB, EMBED_SIZE, HIDDEN_SIZE, NUM_LAYERS)\n",
        "model = Seq2Seq(encoder, decoder).to(DEVICE)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_sp.pad_id())\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(model, train_loader, optimizer, criterion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bleu(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ5gh9th0ttn",
        "outputId": "90f52a92-e741-4cf8-d3e6-e02cd16f2964"
      },
      "id": "zZ5gh9th0ttn",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.2394\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}